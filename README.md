# DocSage â€“ AI Knowledge Base Agent

## 1. Overview

DocSage is an AI-powered Knowledge Base Agent built for the **AI Agent Development Challenge (Rooman)**.

It allows a user to:

1. **Upload a PDF or text document**
2. **Ask natural language questions about it**
3. Get answers generated by **Google Gemini**, using only the content of the uploaded document.

The goal is to reduce the time people spend manually searching long HR/operations PDFs and turn them into an interactive Q&A experience.

> Category: **Business Operations â€“ Knowledge Base Agent**

---

## 2. Features

- ðŸ“„ **Document Upload**
  - Upload PDF or TXT files through a modern, ChatGPT-style web UI.
  - Drag-and-drop or click-to-upload workflow.

- ðŸ’¬ **Chat with Your Document**
  - Ask questions in natural language after the document is processed.
  - Answers are generated using **Gemini**, guided to stick to the document content.

- âš ï¸ **Graceful Handling for Empty/Bad PDFs**
  - If the uploaded file has no extractable text (e.g. scanned PDF or malformed file), the app returns a clear error instead of crashing (e.g., PyPDF2 `EOF marker not found`).

- ðŸŽ¨ **Modern UI**
  - Single-page HTML/CSS/JS frontend inspired by ChatGPT:
    - Hero-style landing screen for upload
    - Smooth transition into a chat interface once the file is processed

---

## 3. Tech Stack

- **AI Model**
  - Google Gemini (via `google-generativeai`)

- **Backend**
  - Python, Flask, Flask-CORS
  - PyPDF2 for text extraction from PDFs

- **Frontend**
  - HTML5, CSS3, Vanilla JavaScript

- **Environment / Config**
  - `python-dotenv` for local API key loading

*(If you later add embeddings, vector DB, or visualization, you can expand this section.)*

---

## 4. Architecture

High-level flow:

1. **User uploads a document (PDF/TXT)** from the frontend.
2. **Flask backend** receives the file:
   - Uses **PyPDF2** (or text decoding) to extract text.
   - Stores the extracted text in memory as the current **knowledge base**.
3. **User asks a question** in the chat interface.
4. Backend builds a prompt:
   - Includes the document text as context.
   - Includes the userâ€™s question.
   - Asks Gemini to answer *only* from the document or say it cannot find the answer.
5. **Gemini returns an answer**, which is sent back to the frontend.
6. Frontend displays the conversation in a chat-style UI.

> Currently, the storage is in-memory. When the server restarts, the knowledge base is cleared.

### (Optional) Mermaid Architecture Diagram

You can include this in the README (GitHub will render it if Mermaid is enabled) or use it as a base to draw your own diagram:

```mermaid
graph TD
    User[User / Browser] -->|Upload PDF/TXT| Frontend[HTML/CSS/JS UI]
    Frontend -->|POST /upload (file)| Flask[Flask Backend]

    Flask -->|Extract text| PDF[PyPDF2 / Text Parser]
    PDF --> KB[In-memory Knowledge Base]

    User -->|Ask Question| Frontend
    Frontend -->|POST /ask (question)| Flask
    Flask -->|Prompt with Document Text + Question| Gemini[Google Gemini API]
    Gemini -->|Answer| Flask
    Flask -->|JSON Response| Frontend
    Frontend -->|Render Chat UI| User
